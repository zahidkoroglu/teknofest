REPUBLIC OF TURKEYYILDIZ TECHNICAL UNIVERSITYFACULTY OF ELECTRICAL-ELECTRONICS ENGINEERINGDEPARTMENT OF CONTROL AND AUTOMATION ENGINEERINGGRADUATION PROJECTEKF-SLAM BASED INDOOR NAVIGATIONAdvisor: [Your Advisor's Name]Student(s): [Your Name(s) and Student Number(s)]Istanbul, 2024ABSTRACTSimultaneous Localization and Mapping (SLAM) is a fundamental challenge for autonomous mobile robots operating in unknown environments. This project presents the design, implementation, and analysis of a complete indoor navigation system centered around an Extended Kalman Filter (EKF) based SLAM algorithm. The system integrates odometry data with sensor measurements to concurrently build a map of the environment and estimate the robot's pose within it. The mapping approach is twofold, combining a feature-based method using landmarks with a dense representation through an occupancy grid. For the feature-based map, landmarks are detected from laser scan data using a clustering and circle-fitting pipeline. Data association is handled using the Mahalanobis distance to correctly correlate observations with known landmarks. Once a consistent map is generated, global path planning is achieved using A*, RRT, and Dijkstra's algorithms, which compute collision-free paths on the created occupancy grid. This report details the theoretical foundations, mathematical models, and system architecture, and outlines the experimental results required to validate the system's performance in both simulated and real-world scenarios.Keywords: EKF-SLAM, Extended Kalman Filter, Mobile Robotics, Indoor Navigation, Landmark Detection, Occupancy Grid, Path Planning, A*, RRT, DijkstraÖNSÖZBu bitirme çalışmasının her aşamasında değerli bilgi ve tecrübeleriyle yol gösteren danışman hocamız [Your Advisor's Name]'e teşekkürlerimizi sunarız. Proje süresince desteklerini esirgemeyen Kontrol ve Otomasyon Mühendisliği Bölümü'ndeki tüm hocalarımıza ve arkadaşlarımıza teşekkür ederiz.(If applicable) Bu çalışma, TÜBİTAK BİDEB [2209A / 2209B] programı tarafından desteklenmiştir. Desteklerinden dolayı TÜBİTAK'a teşekkür ederiz.[Your Name(s)]Haziran, 2024CONTENTSINTRODUCTION1.1. Literature Survey1.2. Objective of the StudyTHEORETICAL BACKGROUND AND SYSTEM MODELING2.1. The SLAM Problem2.2. Probabilistic Robotics Foundation2.3. The Extended Kalman Filter (EKF)2.4. Robot Motion and Odometry Model2.5. Sensor Measurement ModelSYSTEM ARCHITECTURE AND IMPLEMENTATION3.1. EKF-SLAM Algorithm3.2. Landmark-Based Mapping3.3. Occupancy Grid Mapping3.4. Fusing SLAM with Occupancy Grid Mapping3.5. System Hardware and Software PlatformPATH PLANNING4.1. A* Algorithm4.2. Rapidly-exploring Random Tree (RRT)4.3. Dijkstra's AlgorithmREALISTIC DESIGN CONSTRAINTSRESULTS AND DISCUSSIONS6.1. Simulation Results6.2. Real-World Experimental Results6.3. Performance BenchmarksCONCLUSIONREFERENCESAPPENDICESLIST OF SYMBOLSSymbolDescriptionxk​State vector at time kx^k​Estimated state vector at time kξt​Augmented state vector (robot pose + map)μMean of a Gaussian distributionΣCovariance matrix of a Gaussian distributionuk​Control vector (body twist) at time kzk​Measurement vector at time kg(⋅)Nonlinear state transition function (motion model)h(⋅)Nonlinear measurement function (sensor model)Ak​Jacobian of the motion model w.r.t. stateHk​Jacobian of the measurement model w.r.t. stateQProcess noise covarianceRMeasurement noise covarianceKk​Kalman Gain at time kTab​Homogeneous transformation from frame {b} to {a}Vb​Body twist of the robotϕl​,ϕr​Left and right wheel anglesLIST OF ABBREVIATIONSAbbreviationDescriptionSLAMSimultaneous Localization and MappingEKFExtended Kalman FilterROSRobot Operating SystemIMUInertial Measurement UnitRRTRapidly-exploring Random TreeATEAbsolute Trajectory ErrorPDFProbability Density FunctionLIST OF FIGURES[Figure 2.1: The recursive nature of Bayesian filtering.][Figure 2.2: Differential drive robot model with body and wheel frames.][Figure 3.1: The structure of the augmented state vector in EKF-SLAM.][Figure 3.2: Landmark detection pipeline from raw laser scan.][Figure 3.3: Occupancy grid map representation.][Figure 5.1: Simulation environment with robot and landmarks.][Figure 5.2: Comparison of ground truth, odometry, and SLAM-estimated trajectories in simulation.][Figure 5.3: Final landmark map from simulation vs. ground truth.][Figure 5.4: Final occupancy grid map generated in simulation.][Figure 5.5: Robot setup for real-world experiments.][Figure 5.6: Trajectory and map generated from a real-world experiment.][Figure 5.7: Occupancy grid generated from a real-world run.]LIST OF TABLES[Table 5.1: Absolute Trajectory Error (ATE) for simulation runs.][Table 5.2: Path planner performance comparison on a sample map.][Table 5.3: Final pose error for multiple real-world trials.]SECTION 1: INTRODUCTION1.1 Literature SurveyFor a mobile robot to operate autonomously in an unknown or dynamic environment, it must answer two fundamental questions simultaneously: "Where am I?" and "What does my environment look like?". The process of answering these coupled questions is known as Simultaneous Localization and Mapping (SLAM). Without a map, a robot cannot determine its location, and without knowing its location, it cannot build a consistent map. This "chicken-and-egg" problem has been a central focus of robotics research for decades.Early approaches to SLAM were dominated by probabilistic methods, with the Extended Kalman Filter (EKF) being one of the first and most influential solutions. The seminal work by Smith, Self, and Cheeseman established the use of the EKF to maintain a map of geometric features, where both the robot's pose and the feature locations were part of a single, large state vector. While powerful, this approach suffers from several key limitations. Its computational complexity is quadratic with respect to the number of landmarks, as the covariance matrix grows, making it unsuitable for large-scale environments. Furthermore, the EKF relies on a Gaussian noise assumption and can be prone to divergence if its linearization assumptions are strongly violated.To address these limitations, various other SLAM paradigms have emerged. Particle Filters, as used in FastSLAM, offered a way to represent non-Gaussian, multi-modal probability distributions. This makes them more robust to ambiguity in data association but at a higher computational cost and susceptibility to particle deprivation. More recently, graph-based optimization methods (GraphSLAM) have become the standard for large-scale mapping. These methods formulate SLAM as a nonlinear least-squares problem, representing the robot's trajectory and map features as nodes in a graph connected by constraints from odometry and sensor measurements. Graph-based SLAM is generally more accurate and scalable than filter-based methods but is often performed as a batch optimization, making it less suitable for online, real-time applications without incremental extensions.Despite these advancements, EKF-SLAM remains a foundational algorithm with significant value. It is an online, recursive filter that does not require storing the entire history of poses and measurements, making it suitable for systems with limited memory. For applications with a moderate number of distinct environmental features, such as the indoor navigation task addressed in this project, its computational efficiency and well-understood probabilistic formulation make it an excellent choice.1.2 Objective of the StudyThe objective of this project is to design, implement, and evaluate a comprehensive indoor navigation system for a differential drive mobile robot. The core of this system is an Extended Kalman Filter (EKF) based SLAM algorithm.The system will be capable of:State Estimation: Fusing wheel odometry data with external sensor measurements to provide a robust estimate of the robot's pose (x^,y^​,θ^).Dual-Modality Mapping: Concurrently constructing two types of maps:A sparse landmark-based map, where the locations of distinct environmental features are estimated and tracked within the EKF's state vector.A dense occupancy grid map, which represents the environment as a grid of cells, each with a probability of being occupied, free, or unknown.Path Planning: Utilizing the generated occupancy grid map to compute collision-free paths from a start to a goal configuration using three distinct planning algorithms: A*, RRT, and Dijkstra.The performance of the SLAM algorithm will be benchmarked against ground truth (in simulation) and pure odometry to quantify its accuracy and consistency. The path planning algorithms will be compared based on path length and computation time.SECTION 2: THEORETICAL BACKGROUND AND SYSTEM MODELING2.1 The SLAM ProblemThe problem of Simultaneous Localization and Mapping (SLAM) is a cornerstone of mobile robotics. It addresses the challenge a robot faces when navigating an unknown environment without access to an external positioning system like GPS. The robot must incrementally build a map of its surroundings while simultaneously using that same map to determine its own location.This creates a fundamental "chicken-and-egg" dilemma:To build an accurate map, the robot must know its precise location. If the robot's pose is uncertain, sensor measurements will be registered incorrectly, leading to a distorted and inconsistent map.To accurately localize itself, the robot needs a consistent map of the environment to compare its sensor readings against.Therefore, the localization and mapping problems are coupled and must be solved concurrently. The goal of a SLAM system is to take a time series of control inputs u1:k​ and sensor measurements z1:k​ and produce an estimate of the robot's trajectory x1:k​ along with a map of the environment m. Probabilistically, this is expressed as finding the posterior distribution:P(x1:k​,m∣z1:k​,u1:k​)(2.1)EKF-SLAM, as an online algorithm, focuses on estimating the current state of the robot and the map, simplifying the problem to:P(xk​,m∣z1:k​,u1:k​)(2.2)This makes the problem computationally tractable for real-time applications by avoiding the need to re-evaluate the entire past trajectory with each new measurement.2.2 Probabilistic Robotics FoundationThe entire system is built upon the principles of probabilistic state estimation, which provides a framework for dealing with the inherent uncertainty in sensor data and robot motion. The core idea is to represent the robot's belief about its state and the world not as single, definite values, but as probability distributions. The estimation process is a recursive cycle of prediction and update, governed by Bayes' Theorem. For continuous state spaces, this is expressed in terms of probability density functions (PDFs):fX​(x∣z)=fZ​(z)fZ​(z∣x)fX​(x)​(2.3)This can be broken down into the familiar Bayesian filtering cycle:posteriorP(xk​∣z1:k​)​​∝likelihoodP(zk​∣xk​)​​prior∫P(xk​∣xk−1​)P(xk−1​∣z1:k−1​)dxk−1​​​(2.4)Prediction (Prior): The prior is our belief about the current state before incorporating the latest sensor measurement. It is formed by applying the motion model to the previous posterior belief. This step predicts where the robot will be after a control action, which inherently increases the uncertainty in our estimate.Correction (Likelihood & Posterior): The new sensor measurement, zk​, provides fresh information about the environment. The likelihood, P(zk​∣xk​), quantifies how probable that measurement is, given a hypothetical state xk​. This likelihood is used to update the prior belief, resulting in the posterior belief, P(xk​∣z1:k​). This step corrects the prediction and typically reduces uncertainty.2.3 The Extended Kalman Filter (EKF)The standard Kalman Filter provides an optimal solution for state estimation in linear systems with Gaussian noise. However, robot motion and sensor models are typically nonlinear. The EKF extends the Kalman Filter to handle such systems. It does this by linearizing the nonlinear models around the current best estimate of the state, using a first-order Taylor series expansion. For a system with a nonlinear state transition function g(⋅) and measurement function h(⋅):xk​=g(xk−1​,uk​)+wk​(2.5)zk​=h(xk​)+vk​(2.6)The EKF approximates these functions with their Jacobians. The Jacobian of the motion model with respect to the state is Ak​=∂x∂g​∣x^k−1​,uk​​, and the Jacobian of the measurement model is Hk​=∂x∂h​∣x^k−​​.Prediction Step:The state is propagated forward using the nonlinear motion model:x^k−​=g(x^k−1​,uk​)(2.7)The covariance is propagated using the linearized model (Jacobian Ak​):Σk−​=Ak​Σk−1​AkT​+Q(2.8)Update Step:The Kalman Gain Kk​ is computed to optimally weigh the innovation (the difference between the actual measurement zk​ and the predicted measurement h(x^k−​)):Kk​=Σk−​HkT​(Hk​Σk−​HkT​+R)−1(2.9)The state and covariance are then updated using this gain:x^k​=x^k−​+Kk​(zk​−h(x^k−​))(2.10)Σk​=(I−Kk​Hk​)Σk−​(2.11)where Q and R are the process and measurement noise covariance matrices, respectively.2.4 Robot Motion and Odometry ModelThe motion of the differential drive robot serves as our state transition model, g(⋅). The relationship between the robot's body velocity (twist) and the angular velocities of its wheels is defined by its kinematics. The body twist Vb​=(ωb​,vbx​,vby​)T describes the instantaneous motion of the robot's reference frame. The twist of the body frame can be expressed in the frame of each wheel using the adjoint transformation matrix, Aib​. For a wheel i:Vi​=Aib​Vb​(2.12)For our differential drive robot with left and right wheels, and a half track-width of d, the adjoints are:Alb​=​1−d0​010​001​​,Arb​=​1d0​010​001​​(2.13)This gives the twists in the left and right wheel frames:Vl​=Alb​Vb​=​θ˙vx​−dθ˙vy​​​(2.14)Vr​=Arb​Vb​=​θ˙vx​+dθ˙vy​​​(2.15)For conventional wheels, there is no slipping, so the velocity in the wheel's y-direction is zero (vyi​=0), and the velocity in the x-direction is vxi​=rϕ˙​i​. Substituting these constraints gives the inverse kinematics:ϕ˙​l​=rvx​−dθ˙​(2.16)ϕ˙​r​=rvx​+dθ˙​(2.17)For odometry, we use the forward kinematics. We measure the change in wheel angles from encoders (Δϕl​,Δϕr​) over a timestep Δt, and use this to compute the body twist Vb​ that the robot experienced.Vb​=​ωb​vbx​vby​​​=​−r/(2d)r/20​r/(2d)r/20​​[ϕ˙​l​ϕ˙​r​​](2.18)This calculated twist is our control input uk​=Vb​Δt. It is then integrated to update the robot's pose, giving our nonlinear function g(⋅). If the angular velocity ωb​≈0 (the robot is moving straight):g(x^k−1​,uk​)=​x^k−1,x​+vbx​Δtcos(x^k−1,θ​)x^k−1,y​+vbx​Δtsin(x^k−1,θ​)x^k−1,θ​​​(2.19)If ωb​=0 (the robot is turning):g(x^k−1​,uk​)=​x^k−1,x​+ωb​vbx​​(sin(x^k−1,θ​+ωb​Δt)−sin(x^k−1,θ​))x^k−1,y​+ωb​vbx​​(−cos(x^k−1,θ​+ωb​Δt)+cos(x^k−1,θ​))x^k−1,θ​+ωb​Δt​​(2.20)The Jacobian Ak​ of this model is a 3×3 matrix that captures how small changes in the previous state affect the new state:Ak​=I+​000​000​∂θ∂gx​​∂θ∂gy​​0​​(2.21)2.5 Sensor Measurement ModelThe sensor measurement model, h(⋅), is a function that predicts the expected sensor reading given the current state estimate. In our landmark-based SLAM, the measurement zk​=(r,ϕ)T consists of the range and bearing to a landmark. Given a robot pose (xr​,yr​,θr​) and a landmark position (xm​,ym​), the predicted measurement is:h(x^k​)=[(xm​−xr​)2+(ym​−yr​)2​atan2(ym​−yr​,xm​−xr​)−θr​​](2.22)The Jacobian of this function, Hk​, is a 2×(3+2N) matrix (for N landmarks) that is sparse. It relates small changes in the state (robot pose and landmark positions) to the resulting changes in the measurement. For an observation of landmark j, the non-zero columns of the Jacobian are:Hkj​=[−d​Δx​dΔy​​−d​Δy​−dΔx​​0−1​……​d​Δx​−dΔy​​d​Δy​dΔx​​……​](2.23)where Δx=xmj​​−xr​, Δy=ymj​​−yr​, and d=Δx2+Δy2.SECTION 3: SYSTEM ARCHITECTURE AND IMPLEMENTATION3.1 EKF-SLAM AlgorithmIn EKF-SLAM, the state vector is augmented to include not only the robot's pose but also the positions of all observed landmarks.x=[robot posexr​,yr​,θr​​​,landmark 1m1,x​,m1,y​​​,…,landmark NmN,x​,mN,y​​​]T(3.1)The corresponding covariance matrix Σ represents the uncertainty in the entire system. Crucially, it contains not only the uncertainty of the robot pose and landmark positions but also the cross-correlation terms between them. These correlations are the key to SLAM; observing a known landmark reduces the uncertainty in the robot's pose, which in turn reduces the uncertainty of other, unobserved landmarks correlated with that pose.function EKF_SLAM_Loop(previous_state, previous_covariance, odometry_input, measurements):
  // Prediction Step
  predicted_state = motion_model(previous_state, odometry_input)
  A = jacobian_of_motion_model(previous_state, odometry_input)
  predicted_covariance = A * previous_covariance * A' + process_noise_Q

  // Update Step
  corrected_state = predicted_state
  corrected_covariance = predicted_covariance
  for each measurement z_i in measurements:
    landmark_id = data_association(z_i, corrected_state, corrected_covariance)
    if landmark_id is new:
      initialize_new_landmark(corrected_state, corrected_covariance, z_i)

    predicted_measurement = measurement_model(corrected_state, landmark_id)
    H = jacobian_of_measurement_model(corrected_state, landmark_id)

    K = corrected_covariance * H' * inverse(H * corrected_covariance * H' + measurement_noise_R)

    corrected_state = corrected_state + K * (z_i - predicted_measurement)
    corrected_covariance = (Identity - K * H) * corrected_covariance

  return corrected_state, corrected_covariance
3.2 Landmark-Based MappingThe landmark-based map is created by detecting and tracking cylindrical objects from 2D laser scan data. The process involves several steps:Clustering: Points from the laser scan are grouped into clusters based on Euclidean distance. Points that are close to each other are considered part of the same object.Circle Fitting: A circle is fitted to each valid cluster of points using a least-squares method. This gives an estimate of the landmark's center (a,b) and radius R. This is based on the algebraic fit described by Al-Sharadqah and Chernov, which solves for the parameters of the circle equation:(x−a)2+(y−b)2=R2(3.2)Data Association: When a landmark is detected, it must be associated with an existing landmark in the map or identified as a new one. This is a critical step, as incorrect associations can cause the filter to diverge. This is achieved by calculating the Mahalanobis distance between the new measurement zi​ and the predicted measurements z^k​ for all existing landmarks in the map.DM​(zi​,z^k​)=(zi​−z^k​)TΨk−1​(zi​−z^k​)​(3.3)where Ψk​=Hk​Σk−​HkT​+R is the innovation covariance. The measurement is associated with the landmark that has the smallest Mahalanobis distance, provided it is below a certain threshold. If no existing landmark is a good match, a new landmark is initialized and added to the state.3.3 Occupancy Grid MappingIn parallel with landmark mapping, an occupancy grid map is generated. This provides a dense representation of the environment, which is essential for collision-free path planning. The map is a 2D grid where each cell mi​ stores the probability of it being occupied, P(mi​∣z1:k​). A key challenge is that probabilities are bounded between [0, 1], which can lead to numerical instability and saturation issues during updates. To resolve this, we use the log-odds representation. The log-odds l(mi​) of a cell is defined as:l(mi​)=log1−P(mi​∣z1:k​)P(mi​∣z1:k​)​(3.4)This transformation maps the probability from [0, 1] to the real number line (−∞,∞). A log-odds value of 0 corresponds to a probability of 0.5 (unknown). The Bayesian update rule becomes a simple addition in the log-odds space:lk,i​=lk−1,i​+inverse_sensor_model(mi​,xk​,zk​)−l0​(3.5)where lk−1,i​ is the previous log-odds value, l0​ is the prior log-odds (typically 0), and the inverse sensor model provides the update value. For a laser scanner, the inverse sensor model defines two values:locc​: A positive value added to a cell's log-odds if a laser beam endpoint falls within it, increasing its probability of being occupied.lfree​: A negative value added to a cell's log-odds if a laser beam passes through it, increasing its probability of being free.3.4 Fusing SLAM with Occupancy Grid MappingThe two mapping approaches—landmark-based EKF and occupancy grid—are not independent; they are fused to create a robust system. The landmark-based EKF provides a globally consistent estimate of the robot's pose, which is essential for building an accurate occupancy grid.If the occupancy grid were built using only raw odometry data, it would quickly become distorted. As the robot moves, small errors in wheel encoders accumulate, causing the odometry pose to drift from the true pose. This drift would result in features like walls appearing smeared or duplicated in the grid map.To prevent this, we leverage the pose estimate x^k​=(x^k​,y^​k​,θ^k​) from the EKF-SLAM filter. This pose has been corrected by landmark observations and is anchored to a globally consistent map frame. Each laser scan, which is measured in the robot's local frame, is transformed into the global map frame using this corrected pose before being used to update the occupancy grid. For a laser scan point probot​=[xscan​,yscan​]T in the robot's frame, its position in the map frame pmap​ is calculated as:pmap​=[cos(θ^k​)sin(θ^k​)​−sin(θ^k​)cos(θ^k​)​]probot​+[x^k​y^​k​​](3.6)By using the SLAM-corrected pose for this transformation, we ensure that the occupancy grid is built in a consistent global frame, free from the cumulative errors of odometry.3.5 System Hardware and Software PlatformThe experimental validation of this project was conducted on a TurtleBot3 Burger mobile robot. This platform was chosen for its accessibility, well-supported ROS integration, and suitable sensor suite for indoor SLAM.Hardware Platform: The TurtleBot3 Burger is a compact, two-wheeled differential drive robot. Its key hardware components include:Actuation: Two Dynamixel XL430-W250-T servo motors with integrated wheel encoders, providing both motion and proprioceptive feedback (odometry).Sensing: A 360° 2D laser distance sensor (LDS-01) is the primary exteroceptive sensor used for mapping and landmark detection.Computation: An onboard Raspberry Pi 4 serves as the main computer, running the ROS framework and all high-level navigation nodes.Low-Level Control: An OpenCR 1.0 board interfaces with the motors and sensors, providing a direct hardware abstraction layer.Software Framework: The entire system is built upon the Robot Operating System (ROS 2). ROS provides the necessary middleware for communication between different software modules (nodes), including message passing, service calls, and parameter management. The modularity of ROS allows the SLAM algorithm, mapping processes, and path planners to run as independent yet interconnected nodes.SECTION 4: PATH PLANNINGOnce a consistent occupancy grid map is built, the robot can navigate the environment. This requires a path planner to find a sequence of waypoints from the robot's current location to a specified goal. This project implements and compares three classical graph-search algorithms, which treat the occupancy grid as a graph where grid cells are nodes and adjacent free cells are connected by edges.4.1 A* AlgorithmA* is an informed or "best-first" search algorithm that finds the least-cost path from a start node nstart​ to a goal node ngoal​. It efficiently explores the graph by prioritizing nodes that appear to be on the best path. This is achieved by evaluating each node n with the function:f(n)=g(n)+h(n)(4.1)where:g(n) is the exact cost of the path from the start node to the current node n.h(n) is a heuristic function that estimates the cost of the cheapest path from n to the goal. A common heuristic for grid maps is the Euclidean distance: h(n)=(nx​−ngoal,x​)2+(ny​−ngoal,y​)2​.A* maintains a priority queue of nodes to visit, ordered by the lowest f(n) value. For the heuristic to be admissible (and for A* to guarantee an optimal path), h(n) must never overestimate the actual cost to the goal.function A_Star(start, goal, map):
  open_set = PriorityQueue()
  open_set.add(start, 0)
  came_from = {}
  g_score = {node: infinity for all nodes in map}
  g_score[start] = 0
  f_score = {node: infinity for all nodes in map}
  f_score[start] = heuristic(start, goal)

  while open_set is not empty:
    current = open_set.pop_lowest_f_score()
    if current == goal:
      return reconstruct_path(came_from, current)

    for each neighbor of current:
      tentative_g_score = g_score[current] + dist(current, neighbor)
      if tentative_g_score < g_score[neighbor]:
        came_from[neighbor] = current
        g_score[neighbor] = tentative_g_score
        f_score[neighbor] = tentative_g_score + heuristic(neighbor, goal)
        if neighbor not in open_set:
          open_set.add(neighbor, f_score[neighbor])

  return failure // No path found
4.2 Rapidly-exploring Random Tree (RRT)RRT is a sampling-based algorithm designed for efficient pathfinding in complex, high-dimensional spaces. Unlike grid-based searchers, RRT builds a tree of reachable states by randomly sampling the configuration space. The algorithm proceeds as follows:Sample: Generate a random state qrand​ in the configuration space.Find Nearest: Find the node in the existing tree, qnear​, that is closest to qrand​.Steer: Generate a new state, qnew​, by taking a step of a fixed size ϵ from qnear​ in the direction of qrand​. The steer function can be defined as:qnew​=qnear​+∥qrand​−qnear​∥qrand​−qnear​​ϵ(4.2)Check Collision: If the path from qnear​ to qnew​ is collision-free, add qnew​ to the tree as a child of qnear​.The algorithm repeats until a node is added that is within a certain tolerance of the goal. While not optimal, RRT is probabilistically complete.function RRT(start, goal, max_iterations):
  tree = initialize_tree_with(start)
  for i from 1 to max_iterations:
    q_rand = sample_random_point()
    q_near = find_nearest_node_in_tree(tree, q_rand)
    q_new = steer(q_near, q_rand, step_size)

    if not is_collision(q_near, q_new):
      add_node_and_edge(tree, q_near, q_new)
      if distance(q_new, goal) < goal_threshold:
        return reconstruct_path_from_tree(tree, q_new)

  return failure // No path found
4.3 Dijkstra's AlgorithmDijkstra's algorithm is a classic graph search algorithm that finds the shortest path from a single source node to all other nodes in a graph with non-negative edge weights. It is an uninformed search algorithm, meaning it does not use a heuristic to guide its search. It can be seen as a special case of A* where the heuristic is always zero, h(n)=0. The evaluation function is simply:f(n)=g(n)(4.3)Dijkstra's explores the state space by expanding outward from the start node, always visiting the un-visited node with the lowest accumulated cost g(n). Because it explores uniformly in all directions, it is often less efficient than A* for point-to-point pathfinding but is guaranteed to find the shortest path.function Dijkstra(start, goal, map):
  dist = {node: infinity for all nodes in map}
  prev = {node: null for all nodes in map}
  dist[start] = 0
  Q = PriorityQueue(all nodes in map)

  while Q is not empty:
    u = Q.extract_min_dist()
    if u == goal:
      return reconstruct_path(prev, u)

    for each neighbor v of u:
      alt = dist[u] + length(u, v)
      if alt < dist[v]:
        dist[v] = alt
        prev[v] = u
        Q.decrease_priority(v, alt)

  return failure // No path found
SECTION 5: REALISTIC DESIGN CONSTRAINTSThe development and implementation of this project were subject to several realistic constraints that influenced the design choices and system architecture. These constraints span technical, environmental, and logistical domains.Technical Constraints:Computational Power: The entire SLAM and navigation stack runs on an onboard Raspberry Pi 4. This limitation necessitates the use of computationally efficient algorithms. EKF-SLAM was chosen over more resource-intensive methods like particle filters or full graph-based optimization due to its lower memory footprint and predictable, real-time update steps.Sensor Accuracy and Noise: The LDS-01 LiDAR sensor, while effective, has inherent limitations in range and precision, and is susceptible to noise from reflective or transparent surfaces. Similarly, wheel odometry is prone to drift from wheel slippage, uneven floors, and calibration errors. The probabilistic nature of the EKF is designed specifically to handle and mitigate such noise.Power Consumption: The robot's operational time is limited by its battery capacity. All algorithms must be efficient not only in computation but also in power usage to maximize the duration of experiments.Environmental Constraints:Feature Availability: EKF-SLAM relies on the consistent re-observation of distinct landmarks. The system's performance is therefore dependent on the structure of the environment. In feature-poor environments (e.g., long, empty corridors), the filter's ability to correct for drift is diminished.Dynamic Obstacles: The current implementation assumes a static environment. The presence of unmodeled dynamic obstacles (e.g., people walking) can introduce spurious landmark detections or corrupt laser scans, which can negatively impact the map and localization accuracy.Logistical and Financial Constraints:Budget: The project was developed with a limited budget, which influenced the choice of the cost-effective TurtleBot3 platform. This constraint precludes the use of higher-precision, more expensive sensors that could potentially improve performance.Development Time: The project timeline was constrained by the academic semester, requiring a focus on implementing and validating a core set of reliable algorithms rather than exploring a wider range of more complex, experimental techniques.SECTION 6: RESULTS AND DISCUSSIONSThis section is reserved for the presentation and analysis of the experimental results obtained from both simulation and real-world tests.6.1 Simulation ResultsSimulations were conducted in a controlled environment to validate the core algorithms and provide a baseline for performance. When inserting your results, discuss how the EKF-SLAM trajectory closely follows the ground truth, especially in areas where the odometry-only path shows significant drift. Analyze the final landmark map for accuracy, noting the final estimated positions and their covariance ellipses.6.2 Real-World Experimental ResultsThe system was deployed on a physical TurtleBot3 platform in a laboratory environment with physical cylindrical landmarks. When presenting your results, discuss the challenges encountered, such as non-ideal sensor data or unexpected wheel slip. Analyze the final map and trajectory, highlighting how the SLAM filter successfully built a coherent map despite these real-world imperfections.6.3 Performance BenchmarksTo quantitatively evaluate the system, several metrics were recorded.Localization Accuracy: The Absolute Trajectory Error (ATE) was used to measure the difference between the estimated path and the ground truth path in simulation. When presenting your ATE table, comment on the magnitude of the improvement provided by SLAM over pure odometry.Path Planner Performance: The three path planning algorithms were compared on a representative map generated by the SLAM system. In your analysis, discuss the trade-offs between the algorithms. Note that A* should provide the shortest path with less exploration than Dijkstra's, while RRT may find a longer, less smooth path more quickly, especially in open spaces.SECTION 7: CONCLUSIONThis project successfully demonstrated a complete EKF-SLAM based navigation stack for an indoor mobile robot. The system effectively integrates wheel odometry and laser scan data to build both a sparse landmark map and a dense occupancy grid. The results from simulation and real-world experiments show a significant improvement in localization accuracy when using EKF-SLAM compared to relying on pure wheel odometry, successfully correcting for drift over long trajectories. The generated maps proved suitable for use with classical path planning algorithms—A*, RRT, and Dijkstra—enabling the robot to navigate autonomously from a start to a goal location.Future work could explore more advanced data association techniques to improve robustness in cluttered environments, such as implementing a Joint Compatibility Branch and Bound (JCBB) algorithm. Additionally, integrating other sensor modalities like an IMU could improve the motion model's accuracy. Finally, transitioning from EKF-SLAM to a modern graph-based SLAM system using frameworks like g2o or GTSAM could offer better scalability and consistency for larger, more complex environments.
